{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d45fde81-3997-46e7-b5fa-737b84d4a3f4",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. If you had not, install selenium using `pip install selenium webdriver-manager`\n",
    "2. If you had not, install tqdm using `pip install tqdm`\n",
    "3. instead of storing strings & numbers, or generic objects, it is wiser to store typed objects; two good choices are\n",
    "    1. __[namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple)__\n",
    "    2. __[dataclass](https://docs.python.org/3/library/dataclasses.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53d009c-2cfa-47be-ad50-e4222775ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, List\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "httpHeaders = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.imdb.com/\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "}\n",
    "url = 'https://www.imdb.com/search/title/?title_type=tv_movie,feature&release_date=2024-01-01,2024-12-31&country_of_origin=IE'\n",
    "\n",
    "@dataclass\n",
    "class Director:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class Thespian:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class MovieInfo:\n",
    "    title: str\n",
    "    url: str\n",
    "    imdbRating: Optional[float] = None\n",
    "    imdbVotes: Optional[int] = None\n",
    "    metascore: Optional[int] = None\n",
    "    directors: List[str] = field(default_factory=list)\n",
    "    thespians: List[str] = field(default_factory=list)\n",
    "\n",
    "# Generic logger\n",
    "def logEvent(msg: str, level: str = \"INFO\", filePath: str = \"scrapingLog.log\") -> None:\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "    for line in msg.strip().splitlines():\n",
    "        with open(filePath, 'a') as f:\n",
    "            f.write(f\"{timestamp} [{level}] {line}\\n\")\n",
    "\n",
    "# Error logger shortcut\n",
    "def logError(msg: str, filePath: str = \"scrapingErrors.log\") -> None:\n",
    "    logEvent(msg, level=\"ERROR\", filePath=filePath)\n",
    "\n",
    "# Universal try-catcher with controllable flow\n",
    "def trierCatcher(keepGoing, traceMsg, task, *taskArgs, **taskKwargs):\n",
    "    if not keepGoing:\n",
    "        return (False, None)\n",
    "    try:\n",
    "        result = task(*taskArgs, **taskKwargs)\n",
    "        return (True, result)\n",
    "    except Exception as e:\n",
    "        logError(f\"{traceMsg}\\n{repr(e)}\")\n",
    "        return (False, None)\n",
    "\n",
    "# Extract movie info from current loaded page\n",
    "def tryParseMovieItem(item) -> Optional[MovieInfo]:\n",
    "    try:\n",
    "        titleBlock = item.select_one(\"div.dli-parent h3\")\n",
    "        if not titleBlock:\n",
    "            return None\n",
    "        title = titleBlock.text.strip()\n",
    "        anchor = item.select_one(\"a\")\n",
    "        if not anchor:\n",
    "            return None\n",
    "        url = \"https://www.imdb.com\" + anchor['href'].split('?')[0]\n",
    "\n",
    "        imdbRatingSpan = item.select_one(\"span.ipc-rating-star--rating\")\n",
    "        imdbVotesSpan = item.select_one(\"span.ipc-rating-star--voteCount\")\n",
    "        metascoreSpan = item.select_one(\"span.metacritic-score-box\")\n",
    "\n",
    "        imdbRating = imdbRatingSpan.text if imdbRatingSpan else None\n",
    "        imdbVotes = imdbVotesSpan.text if imdbVotesSpan else None\n",
    "        metascore = metascoreSpan.text if metascoreSpan else None\n",
    "\n",
    "        return MovieInfo(title=title, url=url, imdbRating=imdbRating, imdbVotes=imdbVotes, metascore=metascore)\n",
    "    except Exception as e:\n",
    "        logError(f\"Error parsing a movie item: {repr(e)}\")\n",
    "        return None\n",
    "\n",
    "def extractMoviesFromPage(pageSource: str) -> List[MovieInfo]:\n",
    "    soup = BeautifulSoup(pageSource, 'html.parser')\n",
    "    movieItems = soup.select(\"ul.ipc-metadata-list > li\")\n",
    "    movieBatch = []\n",
    "    for item in movieItems:\n",
    "        if len(item.attrs) == 1:\n",
    "            movie = tryParseMovieItem(item)\n",
    "            if movie:\n",
    "                movieBatch.append(movie)\n",
    "    return movieBatch\n",
    "\n",
    "def getBrowser(someURL):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(someURL)\n",
    "    return driver    \n",
    "\n",
    "def scrapeIMDbMoviesWithSlidingWindow(someURL: str) -> List[MovieInfo]:\n",
    "    movieList = []\n",
    "    batchCounter = 0\n",
    "    defaultBatchSize = 50\n",
    "    pageBatchSize = 50\n",
    "    sleepTimeSeconds = 0.5\n",
    "    driverWaitTimeout = 10\n",
    "    keepGoing = True\n",
    "    nMoreButtonText = \"ipc-see-more__button\"\n",
    "    buttonTextRetrievalJSCommand = \"return arguments[0].innerText;\"\n",
    "    domPruningJSCommand = \"\"\"\n",
    "            const ul = document.querySelector(\"ul.ipc-metadata-list\");\n",
    "            const lis = ul.querySelectorAll(\"li\");\n",
    "            for (let i = 0; i < 50 && i < lis.length; i++) { lis[i].remove(); }\n",
    "        \"\"\"\n",
    "    clicketyJSCommand = \"arguments[0].click();\"\n",
    "    scrollJSCommand = \"arguments[0].scrollIntoView({block: 'center'});\"\n",
    "    metadataList = \"ipc-metadata-list-summary-item\"\n",
    "    pruningFailMsg = \"JS movie LI cleanup failure\"\n",
    "    movieExtractionFailMsg = \"Failed to extract movies from page\"\n",
    "    movieExtensionFailMsg = \"Failed to append new movies\"\n",
    "    clickFailMsg = \"Clickety failure\"\n",
    "    loadFailMsg = \"New movie load wait failure\"\n",
    "    scrollFailMsg = \"Scroll failure\"\n",
    "    batchSizeFailMsg = \"Batch size update failure\"\n",
    "    sleepFailMsg = \"Sleep failure\"\n",
    "    buttonFailMsg = \"Button retrieval failure\"\n",
    "    buttonTextFailMsg = \"Button text fetch failure\"\n",
    "    driver = getBrowser(someURL)\n",
    "\n",
    "    while keepGoing:\n",
    "        keepGoing, newMovies = trierCatcher(keepGoing, movieExtractionFailMsg, extractMoviesFromPage, driver.page_source)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, movieExtensionFailMsg, movieList.extend, newMovies)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, pruningFailMsg, driver.execute_script, domPruningJSCommand)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, button = trierCatcher(keepGoing, buttonFailMsg, WebDriverWait(driver, driverWaitTimeout).until, EC.element_to_be_clickable((By.CLASS_NAME, nMoreButtonText)))\n",
    "        keepGoing, buttonText = trierCatcher(keepGoing, buttonTextFailMsg, driver.execute_script, buttonTextRetrievalJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, scrollFailMsg, driver.execute_script, scrollJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, clickFailMsg, driver.execute_script, clicketyJSCommand, button)\n",
    "        keepGoing, match = trierCatcher(keepGoing, batchSizeFailMsg, re.search, r\"(\\d+)\", buttonText)\n",
    "        pageBatchSize = int(match.group(1)) if keepGoing and match else defaultBatchSize\n",
    "        keepGoing, _ = trierCatcher(keepGoing, loadFailMsg, WebDriverWait(driver, driverWaitTimeout).until, lambda d: len(d.find_elements(By.CLASS_NAME, metadataList)) >= pageBatchSize)\n",
    "    driver.quit()\n",
    "    return movieList\n",
    "\n",
    "movies = scrapeIMDbMoviesWithSlidingWindow(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0be0058b-559a-4190-9acc-43ed62574e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeMovieCredits(movieURL: str) -> tuple[List[Director], List[Thespian]]:\n",
    "    fullCreditsURL = movieURL + \"fullcredits/\"\n",
    "    directors = []\n",
    "    thespians = []\n",
    "    try:\n",
    "        response = requests.get(fullCreditsURL, headers=httpHeaders)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve full credits page for {movieURL}\\n{repr(e)}\")\n",
    "        return (directors, thespians)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # --- DIRECTORS ---\n",
    "    try:\n",
    "        director_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-director\"})\n",
    "        if director_section:\n",
    "            ul = director_section.find(\"ul\")\n",
    "            if ul:\n",
    "                for li in ul.find_all(\"li\", recursive=False):\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        directors.append(Director(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing directors for {movieURL}\\n{repr(e)}\")\n",
    "        \n",
    "    # --- CAST (limited to top 5) ---\n",
    "    try:\n",
    "        cast_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-cast\"})\n",
    "        if cast_section:\n",
    "            ul = cast_section.find(\"ul\")\n",
    "            if ul:\n",
    "                cast_lis = ul.find_all(\"li\", class_=\"full-credits-page-list-item\", recursive=False)[:5]\n",
    "                for li in cast_lis:\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        thespians.append(Thespian(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing cast for {movieURL}\\n{repr(e)}\")\n",
    "\n",
    "    return (directors, thespians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ad6414-1f0b-48d1-ac34-23092d3070d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/98 [00:05<08:19,  5.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m movie \u001b[38;5;129;01min\u001b[39;00m tqdm(movies):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     directors, thespians = \u001b[43mscrapeMovieCredits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovie\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     movie.directors = directors\n\u001b[32m      7\u001b[39m     movie.thespians = thespians\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mscrapeMovieCredits\u001b[39m\u001b[34m(movieURL)\u001b[39m\n\u001b[32m      4\u001b[39m thespians = []\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullCreditsURL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttpHeaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     response.raise_for_status()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\requests\\adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\http\\client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\http\\client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\http\\client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Samuel\\anaconda3\\envs\\programming\\Lib\\ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "for movie in tqdm(movies):\n",
    "    directors, thespians = scrapeMovieCredits(movie.url)\n",
    "    movie.directors = directors\n",
    "    movie.thespians = thespians\n",
    "    time.sleep(0.5)  # Respect IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64640287-df10-4eef-b348-f8a214f396fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bd41a-7d48-4fca-9de7-adc6eb09eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MovieInfo(title='1. Bring Them Down', url='https://www.imdb.com/title/tt14186876/', imdbRating='6.5', imdbVotes='\\xa0(2.2K)', metascore='63', directors=[Director(name='Chris Andrews', url='https://www.imdb.com/name/nm1643216/'), Director(name='Chris Andrews', url='https://www.imdb.com/name/nm1643216/'), Director(name='Jonathan Hourigan', url='https://www.imdb.com/name/nm1509306/')], thespians=[Thespian(name='Chris Andrews', url='https://www.imdb.com/name/nm1643216/')]), MovieInfo(title='2. Oddity', url='https://www.imdb.com/title/tt26470109/', imdbRating='6.7', imdbVotes='\\xa0(42K)', metascore='78', directors=[Director(name='Damian Mc Carthy', url='https://www.imdb.com/name/nm3374835/')], thespians=[Thespian(name='Damian Mc Carthy', url='https://www.imdb.com/name/nm3374835/')]), MovieInfo(title='3. Small Things Like These', url='https://www.imdb.com/title/tt27196021/', imdbRating='6.8', imdbVotes='\\xa0(22K)', metascore='82', directors=[Director(name='Enda Walsh', url='https://www.imdb.com/name/nm0909629/'), Director(name='Claire Keegan', url='https://www.imdb.com/name/nm10668488/')], thespians=[Thespian(name='Tim Mielants', url='https://www.imdb.com/name/nm2139803/')]), MovieInfo(title='4. Kinds of Kindness', url='https://www.imdb.com/title/tt22408160/', imdbRating='6.5', imdbVotes='\\xa0(59K)', metascore='64', directors=[Director(name='Yorgos Lanthimos', url='https://www.imdb.com/name/nm0487166/'), Director(name='Efthimis Filippou', url='https://www.imdb.com/name/nm3328207/')], thespians=[Thespian(name='Yorgos Lanthimos', url='https://www.imdb.com/name/nm0487166/')]), MovieInfo(title='5. The Watched', url='https://www.imdb.com/title/tt26736843/', imdbRating='5.7', imdbVotes='\\xa0(56K)', metascore='46', directors=[Director(name='Ishana Shyamalan', url='https://www.imdb.com/name/nm10064730/'), Director(name='A.M. Shine', url='https://www.imdb.com/name/nm14564101/')], thespians=[Thespian(name='Ishana Shyamalan', url='https://www.imdb.com/name/nm10064730/')]), MovieInfo(title='6. Kneecap', url='https://www.imdb.com/title/tt27367464/', imdbRating='7.6', imdbVotes='\\xa0(17K)', metascore='76', directors=[Director(name='Rich Peppiatt', url='https://www.imdb.com/name/nm5441396/'), Director(name='Móglaí Bap', url='https://www.imdb.com/name/nm13399201/'), Director(name='Mo Chara', url='https://www.imdb.com/name/nm13399200/'), Director(name='DJ Próvai', url='https://www.imdb.com/name/nm13399202/')], thespians=[Thespian(name='Rich Peppiatt', url='https://www.imdb.com/name/nm5441396/')]), MovieInfo(title='7. The Damned', url='https://www.imdb.com/title/tt15010692/', imdbRating='5.7', imdbVotes='\\xa0(3.9K)', metascore='64', directors=[Director(name='Jamie Hannigan', url='https://www.imdb.com/name/nm2976806/'), Director(name='Thordur Palsson', url='https://www.imdb.com/name/nm4684113/')], thespians=[Thespian(name='Thordur Palsson', url='https://www.imdb.com/name/nm4684113/')]), MovieInfo(title='8. Bonhoeffer', url='https://www.imdb.com/title/tt26237514/', imdbRating='6.3', imdbVotes='\\xa0(3.5K)', metascore='43', directors=[Director(name='Todd Komarnicki', url='https://www.imdb.com/name/nm0464548/')], thespians=[Thespian(name='Todd Komarnicki', url='https://www.imdb.com/name/nm0464548/')]), MovieInfo(title='9. Four Mothers', url='https://www.imdb.com/title/tt19391518/', imdbRating='7.4', imdbVotes='\\xa0(152)', metascore=None, directors=[Director(name='Colin Thornton', url='https://www.imdb.com/name/nm2050907/'), Director(name='Darren Thornton', url='https://www.imdb.com/name/nm1802381/')], thespians=[Thespian(name='Darren Thornton', url='https://www.imdb.com/name/nm1802381/')]), MovieInfo(title='10. The Ghost', url='https://www.imdb.com/title/tt16350410/', imdbRating='6.3', imdbVotes='\\xa0(116)', metascore=None, directors=[Director(name='John Farrelly', url='https://www.imdb.com/name/nm5597474/')], thespians=[Thespian(name='John Farrelly', url='https://www.imdb.com/name/nm5597474/')]), MovieInfo(title='11. Irish Wish', url='https://www.imdb.com/title/tt21957774/', imdbRating='5.2', imdbVotes='\\xa0(21K)', metascore='46', directors=[Director(name='Kirsten Hansen', url='https://www.imdb.com/name/nm0360937/')], thespians=[Thespian(name='Janeen Damian', url='https://www.imdb.com/name/nm0078943/')]), MovieInfo(title='12. The Problem with People', url='https://www.imdb.com/title/tt10013512/', imdbRating='5.8', imdbVotes='\\xa0(393)', metascore=None, directors=[Director(name='Wally Marzano-Lesnevich', url='https://www.imdb.com/name/nm2805298/'), Director(name='Paul Reiser', url='https://www.imdb.com/name/nm0001663/')], thespians=[Thespian(name='Chris Cottam', url='https://www.imdb.com/name/nm1496020/')]), MovieInfo(title='13. September Says', url='https://www.imdb.com/title/tt29315015/', imdbRating='6.4', imdbVotes='\\xa0(351)', metascore='46', directors=[Director(name='Daisy Johnson', url='https://www.imdb.com/name/nm15574095/'), Director(name='Ariane Labed', url='https://www.imdb.com/name/nm3987673/')], thespians=[Thespian(name='Ariane Labed', url='https://www.imdb.com/name/nm3987673/')]), MovieInfo(title='14. Frewaka', url='https://www.imdb.com/title/tt27828550/', imdbRating='6.3', imdbVotes='\\xa0(151)', metascore=None, directors=[Director(name='Aislinn Clarke', url='https://www.imdb.com/name/nm5240404/')], thespians=[Thespian(name='Aislinn Clarke', url='https://www.imdb.com/name/nm5240404/')]), MovieInfo(title=\"15. Brendan Gleeson's Farewell to Hughes's\", url='https://www.imdb.com/title/tt35460312/', imdbRating='6.1', imdbVotes='\\xa0(19)', metascore=None, directors=[], thespians=[Thespian(name='Ciarán Ó Maonaigh', url='https://www.imdb.com/name/nm16925541/')]), MovieInfo(title='16. Amongst the Wolves', url='https://www.imdb.com/title/tt32486316/', imdbRating='6.5', imdbVotes='\\xa0(28)', metascore=None, directors=[Director(name='Luke McQuillan', url='https://www.imdb.com/name/nm8332410/'), Director(name=\"Mark O'Connor\", url='https://www.imdb.com/name/nm4204584/')], thespians=[Thespian(name=\"Mark O'Connor\", url='https://www.imdb.com/name/nm4204584/')]), MovieInfo(title=\"17. Ransom '79\", url='https://www.imdb.com/title/tt30327702/', imdbRating='9.2', imdbVotes='\\xa0(20)', metascore=None, directors=[Director(name='Charlie Bird', url='https://www.imdb.com/name/nm2166460/'), Director(name='Colin Murphy', url='https://www.imdb.com/name/nm6609991/'), Director(name='Colm Quinn', url='https://www.imdb.com/name/nm2897818/')], thespians=[Thespian(name='Colm Quinn', url='https://www.imdb.com/name/nm2897818/')]), MovieInfo(title=\"18. Blue Road: The Edna O'Brien Story\", url='https://www.imdb.com/title/tt33059722/', imdbRating='8.2', imdbVotes='\\xa0(42)', metascore=None, directors=[Director(name=\"Sinéad O'Shea\", url='https://www.imdb.com/name/nm9245602/')], thespians=[Thespian(name=\"Sinéad O'Shea\", url='https://www.imdb.com/name/nm9245602/')]), MovieInfo(title='19. Housewife of the Year', url='https://www.imdb.com/title/tt32813537/', imdbRating='7.7', imdbVotes='\\xa0(48)', metascore=None, directors=[Director(name='Ciaran Cassidy', url='https://www.imdb.com/name/nm2445213/')], thespians=[Thespian(name='Ciaran Cassidy', url='https://www.imdb.com/name/nm2445213/')]), MovieInfo(title='20. Spilt Milk', url='https://www.imdb.com/title/tt15222426/', imdbRating='7.2', imdbVotes='\\xa0(9)', metascore=None, directors=[Director(name='Cara Loftus', url='https://www.imdb.com/name/nm6949689/')], thespians=[Thespian(name='Brian Durnin', url='https://www.imdb.com/name/nm1632987/')]), MovieInfo(title='21. King Frankie', url='https://www.imdb.com/title/tt26752667/', imdbRating='7.8', imdbVotes='\\xa0(73)', metascore=None, directors=[Director(name='Dermot Malone', url='https://www.imdb.com/name/nm7333832/')], thespians=[Thespian(name='Dermot Malone', url='https://www.imdb.com/name/nm7333832/')]), MovieInfo(title='22. Our Blue World: A Water Odyssey', url='https://www.imdb.com/title/tt32365091/', imdbRating='6.7', imdbVotes='\\xa0(21)', metascore=None, directors=[Director(name='Ruán Magan', url='https://www.imdb.com/name/nm0535707/'), Director(name=\"Paul O'Callaghan\", url='https://www.imdb.com/name/nm6669292/')], thespians=[Thespian(name='Ruán Magan', url='https://www.imdb.com/name/nm0535707/')]), MovieInfo(title='23. Kathleen Is Here', url='https://www.imdb.com/title/tt32635252/', imdbRating='7.1', imdbVotes='\\xa0(54)', metascore=None, directors=[Director(name='Eva Birthistle', url='https://www.imdb.com/name/nm0083795/')], thespians=[Thespian(name='Eva Birthistle', url='https://www.imdb.com/name/nm0083795/')]), MovieInfo(title='24. My Sweet Land', url='https://www.imdb.com/title/tt32259705/', imdbRating='7.6', imdbVotes='\\xa0(61)', metascore=None, directors=[Director(name='Sareen Hairabedian', url='https://www.imdb.com/name/nm4821839/')], thespians=[Thespian(name='Sareen Hairabedian', url='https://www.imdb.com/name/nm4821839/')]), MovieInfo(title='25. One Night in Millstreet', url='https://www.imdb.com/title/tt14149106/', imdbRating='7.2', imdbVotes='\\xa0(69)', metascore=None, directors=[Director(name='Lydia Monin', url='https://www.imdb.com/name/nm2900010/')], thespians=[Thespian(name='Andrew Gallimore', url='https://www.imdb.com/name/nm2898894/')]), MovieInfo(title='26. Quintessentially Irish', url='https://www.imdb.com/title/tt31157139/', imdbRating='6.3', imdbVotes='\\xa0(65)', metascore=None, directors=[], thespians=[Thespian(name='Frank Mannion', url='https://www.imdb.com/name/nm0543420/')]), MovieInfo(title='27. Mrs. Robinson', url='https://www.imdb.com/title/tt32576660/', imdbRating='6.9', imdbVotes='\\xa0(29)', metascore=None, directors=[], thespians=[Thespian(name='Aoife Kelleher', url='https://www.imdb.com/name/nm2032969/')]), MovieInfo(title='28. Fidil Ghorm', url='https://www.imdb.com/title/tt31038535/', imdbRating='7.8', imdbVotes='\\xa0(7)', metascore=None, directors=[Director(name='Patricia Forde', url='https://www.imdb.com/name/nm2905209/')], thespians=[Thespian(name='Anne McCabe', url='https://www.imdb.com/name/nm3858648/')]), MovieInfo(title='29. Blurred Lines', url='https://www.imdb.com/title/tt31954861/', imdbRating='9.2', imdbVotes='\\xa0(19)', metascore=None, directors=[Director(name='Mark Agar', url='https://www.imdb.com/name/nm8182901/'), Director(name='Siobhan Aislinn', url='https://www.imdb.com/name/nm14014044/')], thespians=[Thespian(name='Mark Agar', url='https://www.imdb.com/name/nm8182901/')]), MovieInfo(title='30. Birdsong', url='https://www.imdb.com/title/tt32975316/', imdbRating='8.6', imdbVotes='\\xa0(44)', metascore=None, directors=[], thespians=[Thespian(name='Kathleen Harris', url='https://www.imdb.com/name/nm16374081/')]), MovieInfo(title='31. A Want in Her', url='https://www.imdb.com/title/tt33567409/', imdbRating='8.0', imdbVotes='\\xa0(15)', metascore=None, directors=[Director(name='David Barker', url='https://www.imdb.com/name/nm0054862/'), Director(name='Myrid Carten', url='https://www.imdb.com/name/nm10684712/')], thespians=[Thespian(name='Myrid Carten', url='https://www.imdb.com/name/nm10684712/')]), MovieInfo(title='32. Sins of Ireland', url='https://www.imdb.com/title/tt33145227/', imdbRating='8.7', imdbVotes='\\xa0(10)', metascore=None, directors=[Director(name='Kelda Crawford-McCann', url='https://www.imdb.com/name/nm1651741/'), Director(name='Alex Fegan', url='https://www.imdb.com/name/nm3562580/')], thespians=[Thespian(name='Alex Fegan', url='https://www.imdb.com/name/nm3562580/')]), MovieInfo(title='33. The Line', url='https://www.imdb.com/title/tt27418492/', imdbRating='7.1', imdbVotes='\\xa0(9)', metascore=None, directors=[Director(name='Lee Crowley', url='https://www.imdb.com/name/nm10477756/'), Director(name='Pete Daly', url='https://www.imdb.com/name/nm0198500/')], thespians=[Thespian(name='Danny McCafferty', url='https://www.imdb.com/name/nm5932810/')]), MovieInfo(title='34. TWIG', url='https://www.imdb.com/title/tt25505582/', imdbRating='5.4', imdbVotes='\\xa0(16)', metascore=None, directors=[Director(name='Marian Quinn', url='https://www.imdb.com/name/nm0703922/')], thespians=[Thespian(name='Marian Quinn', url='https://www.imdb.com/name/nm0703922/')]), MovieInfo(title='35. I Wish You Were Here', url='https://www.imdb.com/title/tt33384862/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Maria McLeod', url='https://www.imdb.com/name/nm16528054/')], thespians=[Thespian(name='Maria McLeod', url='https://www.imdb.com/name/nm16528054/'), Thespian(name='Hannah Lane', url='https://www.imdb.com/name/nm10132837/')]), MovieInfo(title='36. Swing Bout', url='https://www.imdb.com/title/tt27448139/', imdbRating='8.7', imdbVotes='\\xa0(174)', metascore=None, directors=[Director(name=\"Maurice O'Carroll\", url='https://www.imdb.com/name/nm5984334/')], thespians=[Thespian(name=\"Maurice O'Carroll\", url='https://www.imdb.com/name/nm5984334/')]), MovieInfo(title='37. Wonderland', url='https://www.imdb.com/title/tt4590974/', imdbRating='6.8', imdbVotes='\\xa0(12)', metascore=None, directors=[Director(name='Ciaron Davies', url='https://www.imdb.com/name/nm1076340/'), Director(name='Ensaad Nacer Fawzi', url='https://www.imdb.com/name/nm5141626/')], thespians=[Thespian(name='Ciaron Davies', url='https://www.imdb.com/name/nm1076340/')]), MovieInfo(title='38. Chasing the Light', url='https://www.imdb.com/title/tt34607008/', imdbRating='7.8', imdbVotes='\\xa0(5)', metascore=None, directors=[Director(name=\"Maurice O'Brien\", url='https://www.imdb.com/name/nm2878389/')], thespians=[Thespian(name=\"Maurice O'Brien\", url='https://www.imdb.com/name/nm2878389/')]), MovieInfo(title='39. TerraForma', url='https://www.imdb.com/title/tt28237294/', imdbRating='7.9', imdbVotes='\\xa0(13)', metascore=None, directors=[], thespians=[Thespian(name='Kevin Brennan', url='https://www.imdb.com/name/nm13192165/'), Thespian(name='Laurence Durkin', url='https://www.imdb.com/name/nm7405362/')]), MovieInfo(title=\"40. Don't Forget to Remember\", url='https://www.imdb.com/title/tt31419428/', imdbRating='9.0', imdbVotes='\\xa0(12)', metascore=None, directors=[], thespians=[Thespian(name='Ross Killeen', url='https://www.imdb.com/name/nm2449889/')]), MovieInfo(title='41. Pikmin Forever', url='https://www.imdb.com/title/tt31215789/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Cílan Barrett', url='https://www.imdb.com/name/nm15811959/'), Director(name='Cameron Martin', url='https://www.imdb.com/name/nm15811958/')], thespians=[Thespian(name='Cameron Martin', url='https://www.imdb.com/name/nm15811958/')]), MovieInfo(title='42. Dreamtown', url='https://www.imdb.com/title/tt27919772/', imdbRating='8.5', imdbVotes='\\xa0(10)', metascore=None, directors=[Director(name='Steven Mckenna', url='https://www.imdb.com/name/nm9377259/')], thespians=[Thespian(name='Steven Mckenna', url='https://www.imdb.com/name/nm9377259/')]), MovieInfo(title='43. Froggie', url='https://www.imdb.com/title/tt32764268/', imdbRating='7.4', imdbVotes='\\xa0(12)', metascore=None, directors=[Director(name='Jake Morgan', url='https://www.imdb.com/name/nm6544227/'), Director(name='Luke Morgan', url='https://www.imdb.com/name/nm6544225/')], thespians=[Thespian(name='Luke Morgan', url='https://www.imdb.com/name/nm6544225/')]), MovieInfo(title='44. Life, Once More', url='https://www.imdb.com/title/tt34375868/', imdbRating='8.7', imdbVotes='\\xa0(7)', metascore=None, directors=[Director(name='Mark Agar', url='https://www.imdb.com/name/nm8182901/')], thespians=[Thespian(name=\"Scott O'Keeffe\", url='https://www.imdb.com/name/nm13294295/')]), MovieInfo(title='45. Jackie & Coco', url='https://www.imdb.com/title/tt30957512/', imdbRating='9.5', imdbVotes='\\xa0(11)', metascore=None, directors=[], thespians=[Thespian(name='Gerard Walsh', url='https://www.imdb.com/name/nm5542275/')]), MovieInfo(title='46. The Swimming Diaries', url='https://www.imdb.com/title/tt31612839/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Susan Thomson', url='https://www.imdb.com/name/nm3272613/')], thespians=[Thespian(name='Susan Thomson', url='https://www.imdb.com/name/nm3272613/')]), MovieInfo(title='47. The Cable that Changed the World', url='https://www.imdb.com/title/tt33058129/', imdbRating='7.2', imdbVotes='\\xa0(28)', metascore=None, directors=[Director(name='Ruán Magan', url='https://www.imdb.com/name/nm0535707/')], thespians=[Thespian(name='Ruán Magan', url='https://www.imdb.com/name/nm0535707/')]), MovieInfo(title='48. Eat/Sleep/Cheer/Repeat', url='https://www.imdb.com/title/tt28543787/', imdbRating='7.2', imdbVotes='\\xa0(17)', metascore=None, directors=[], thespians=[Thespian(name='Tanya Doyle', url='https://www.imdb.com/name/nm1975710/')]), MovieInfo(title='49. Stupid August', url='https://www.imdb.com/title/tt34866973/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Padraig Trehy', url='https://www.imdb.com/name/nm6270774/')], thespians=[Thespian(name='Pádraig Trehy', url='https://www.imdb.com/name/nm2412921/')]), MovieInfo(title='50. Anorexia, My Family & Me', url='https://www.imdb.com/title/tt34964956/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Alan Bradley', url='https://www.imdb.com/name/nm4228197/')]), MovieInfo(title='51. A Hell of A Difference', url='https://www.imdb.com/title/tt26768770/', imdbRating='7.2', imdbVotes='\\xa0(19)', metascore=None, directors=[Director(name='Stephen Broekhuizen', url='https://www.imdb.com/name/nm5577555/'), Director(name=\"Emmet O'Brien\", url='https://www.imdb.com/name/nm6190604/')], thespians=[Thespian(name='Stephen Broekhuizen', url='https://www.imdb.com/name/nm5577555/'), Thespian(name=\"Emmet O'Brien\", url='https://www.imdb.com/name/nm6190604/')]), MovieInfo(title='52. Addiction', url='https://www.imdb.com/title/tt33909909/', imdbRating='8.4', imdbVotes='\\xa0(12)', metascore=None, directors=[Director(name='Jonty Ross', url='https://www.imdb.com/name/nm14634229/')], thespians=[Thespian(name='Jonty Ross', url='https://www.imdb.com/name/nm14634229/')]), MovieInfo(title='53. Suit Hung. Tied Tongue.', url='https://www.imdb.com/title/tt18339924/', imdbRating='6.3', imdbVotes='\\xa0(104)', metascore=None, directors=[Director(name='Sau Dachi', url='https://www.imdb.com/name/nm13623325/')], thespians=[Thespian(name='Sau Dachi', url='https://www.imdb.com/name/nm13623325/')]), MovieInfo(title='54. Perennial Light', url='https://www.imdb.com/title/tt30468799/', imdbRating='7.0', imdbVotes='\\xa0(8)', metascore=None, directors=[Director(name='Colin Hickey', url='https://www.imdb.com/name/nm2192714/')], thespians=[Thespian(name='Colin Hickey', url='https://www.imdb.com/name/nm2192714/')]), MovieInfo(title='55. Rory Gallagher: Calling Card', url='https://www.imdb.com/title/tt32576082/', imdbRating='9.0', imdbVotes='\\xa0(9)', metascore=None, directors=[], thespians=[Thespian(name='Brian Reddin', url='https://www.imdb.com/name/nm1469196/')]), MovieInfo(title='56. Burkitt', url='https://www.imdb.com/title/tt33775751/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Éanna Mac Cana', url='https://www.imdb.com/name/nm10485239/')], thespians=[Thespian(name='Éanna Mac Cana', url='https://www.imdb.com/name/nm10485239/')]), MovieInfo(title='57. The Song Cycle', url='https://www.imdb.com/title/tt31164440/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Nick Kelly', url='https://www.imdb.com/name/nm2278921/')], thespians=[Thespian(name='Nick Kelly', url='https://www.imdb.com/name/nm2278921/')]), MovieInfo(title='58. More Than a Whistle', url='https://www.imdb.com/title/tt34378488/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Ronan Cassidy', url='https://www.imdb.com/name/nm6401558/')]), MovieInfo(title='59. Killer Hand Dryer', url='https://www.imdb.com/title/tt32400528/', imdbRating='7.8', imdbVotes='\\xa0(9)', metascore=None, directors=[Director(name='Tracy Cummins', url='https://www.imdb.com/name/nm16155888/')], thespians=[Thespian(name='Tracy Cummins', url='https://www.imdb.com/name/nm16155888/')]), MovieInfo(title='60. Am Fear Liath', url='https://www.imdb.com/title/tt15179926/', imdbRating='5.4', imdbVotes='\\xa0(42)', metascore=None, directors=[Director(name='Pauric Brennan', url='https://www.imdb.com/name/nm3901235/'), Director(name='Mark Hampton', url='https://www.imdb.com/name/nm11798025/')], thespians=[Thespian(name='Pauric Brennan', url='https://www.imdb.com/name/nm3901235/')]), MovieInfo(title='61. The Cry of O Neill', url='https://www.imdb.com/title/tt33839333/', imdbRating='10', imdbVotes='\\xa0(12)', metascore=None, directors=[Director(name='Jonty Ross', url='https://www.imdb.com/name/nm14634229/'), Director(name='Lonan Ross', url='https://www.imdb.com/name/nm14634227/')], thespians=[Thespian(name='Jonty Ross', url='https://www.imdb.com/name/nm14634229/')]), MovieInfo(title='62. The Alexander Complex', url='https://www.imdb.com/title/tt31613951/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Etienne Essery', url='https://www.imdb.com/name/nm8695629/'), Director(name='Neasa Ní Chianáin', url='https://www.imdb.com/name/nm0639107/')], thespians=[Thespian(name='Neasa Ní Chianáin', url='https://www.imdb.com/name/nm0639107/')]), MovieInfo(title='63. Stalked', url='https://www.imdb.com/title/tt34964940/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Alan Bradley', url='https://www.imdb.com/name/nm4228197/')]), MovieInfo(title='64. Andrew Trimble: For Ulster & Ireland', url='https://www.imdb.com/title/tt31229714/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Neil McManus', url='https://www.imdb.com/name/nm15825666/'), Thespian(name='Barry Murphy', url='https://www.imdb.com/name/nm10806548/'), Thespian(name='Mark Thompson', url='https://www.imdb.com/name/nm4829874/'), Thespian(name='Andrew Trimble', url='https://www.imdb.com/name/nm14412510/')]), MovieInfo(title='65. Gama Bomb - Survival of the Fastest', url='https://www.imdb.com/title/tt35069656/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Kiran Acharya', url='https://www.imdb.com/name/nm9046807/')], thespians=[Thespian(name='Kiran Acharya', url='https://www.imdb.com/name/nm9046807/')]), MovieInfo(title='66. Alec Guinness: A Class Act', url='https://www.imdb.com/title/tt33341985/', imdbRating='7.5', imdbVotes='\\xa0(19)', metascore=None, directors=[], thespians=[Thespian(name=\"Brian O'Flaherty\", url='https://www.imdb.com/name/nm2138686/')]), MovieInfo(title='67. Murder of a GAA Chairman', url='https://www.imdb.com/title/tt33064895/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Trevor Birney', url='https://www.imdb.com/name/nm1905185/')]), MovieInfo(title='68. The Disembodied Adventures of Alice', url='https://www.imdb.com/title/tt30061275/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Cléa van der Grijn', url='https://www.imdb.com/name/nm14976821/')], thespians=[Thespian(name='Cléa van der Grijn', url='https://www.imdb.com/name/nm14976821/')]), MovieInfo(title='69. Momentum', url='https://www.imdb.com/title/tt33829028/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Daniel Kiniry', url='https://www.imdb.com/name/nm9483537/'), Director(name='Daniel Kiniry', url='https://www.imdb.com/name/nm16607488/'), Director(name='Doreen Manning', url='https://www.imdb.com/name/nm14627390/'), Director(name=\"Mike O'Dowd\", url='https://www.imdb.com/name/nm5699748/'), Director(name=\"Emma O'Mahony\", url='https://www.imdb.com/name/nm7930048/')], thespians=[Thespian(name='Doreen Manning', url='https://www.imdb.com/name/nm14627390/')]), MovieInfo(title='70. The Reserve', url='https://www.imdb.com/title/tt34288089/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='MJ Whelan', url='https://www.imdb.com/name/nm7197646/')], thespians=[Thespian(name='MJ Whelan', url='https://www.imdb.com/name/nm7197646/')]), MovieInfo(title='71. Getting Lain', url='https://www.imdb.com/title/tt33839263/', imdbRating='8.8', imdbVotes='\\xa0(12)', metascore=None, directors=[Director(name='Feya Rice', url='https://www.imdb.com/name/nm16048158/'), Director(name='Jonty Ross', url='https://www.imdb.com/name/nm14634229/')], thespians=[Thespian(name='Jonty Ross', url='https://www.imdb.com/name/nm14634229/'), Thespian(name='Feya Rice', url='https://www.imdb.com/name/nm16048158/')]), MovieInfo(title='72. Midnight City', url='https://www.imdb.com/title/tt23023498/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Luke Mahony', url='https://www.imdb.com/name/nm14174069/')], thespians=[Thespian(name='Luke Mahony', url='https://www.imdb.com/name/nm14174069/')]), MovieInfo(title='73. HOME: The Story of Zak Moradi', url='https://www.imdb.com/title/tt32919790/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Trevor Whelan', url='https://www.imdb.com/name/nm5299267/')], thespians=[Thespian(name='Trevor Whelan', url='https://www.imdb.com/name/nm5299267/')]), MovieInfo(title='74. The Hegartys of the Laurels', url='https://www.imdb.com/title/tt31630033/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Elizabeth Scanlan', url='https://www.imdb.com/name/nm15904841/')], thespians=[Thespian(name='Catherine Mahon Buckley', url='https://www.imdb.com/name/nm11175365/')]), MovieInfo(title=\"75. L'Irlande, entre terre et mer\", url='https://www.imdb.com/title/tt33643808/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Shane Brennan', url='https://www.imdb.com/name/nm14507368/')]), MovieInfo(title='76. Doctor Who: The Great Delay Again', url='https://www.imdb.com/title/tt36392152/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Mark Teehan', url='https://www.imdb.com/name/nm6330306/')], thespians=[Thespian(name='Paul Cusack', url='https://www.imdb.com/name/nm6030336/')]), MovieInfo(title='77. Remat', url='https://www.imdb.com/title/tt29942919/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Alan Lambert', url='https://www.imdb.com/name/nm1843991/')]), MovieInfo(title='78. The Irish Lumières - The Horgan Brothers', url='https://www.imdb.com/title/tt34387136/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Darina Clancy', url='https://www.imdb.com/name/nm10787827/')]), MovieInfo(title='79. David Puttnam: The Long Way Home', url='https://www.imdb.com/title/tt33065166/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name=\"Edel O'Mahony\", url='https://www.imdb.com/name/nm4978610/')]), MovieInfo(title='80. The Swallow', url='https://www.imdb.com/title/tt33303835/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name=\"Tadhg O'Sullivan\", url='https://www.imdb.com/name/nm2738464/')]), MovieInfo(title='81. At Sea', url='https://www.imdb.com/title/tt32920029/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Sandy Kennedy', url='https://www.imdb.com/name/nm0448320/')], thespians=[Thespian(name='Sandy Kennedy', url='https://www.imdb.com/name/nm0448320/')]), MovieInfo(title='82. Ag Lorg Hy-Brasil', url='https://www.imdb.com/title/tt33481354/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Geoff Power', url='https://www.imdb.com/name/nm13784691/')], thespians=[Thespian(name='Martin Danneels', url='https://www.imdb.com/name/nm1527077/')]), MovieInfo(title='83. The Keepers', url='https://www.imdb.com/title/tt35716311/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Eoin McGowan', url='https://www.imdb.com/name/nm6536263/')]), MovieInfo(title='84. Mammary Mountain', url='https://www.imdb.com/title/tt32986245/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name=\"Maf'j Alvarez\", url='https://www.imdb.com/name/nm16359223/'), Thespian(name='Camille C. Baker', url='https://www.imdb.com/name/nm16359225/'), Thespian(name='Tara Baoth Mooney', url='https://www.imdb.com/name/nm16359224/')]), MovieInfo(title='85. Sinéad', url='https://www.imdb.com/title/tt33064467/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Darragh Byrne', url='https://www.imdb.com/name/nm16217543/'), Thespian(name='David Whelan', url='https://www.imdb.com/name/nm6664323/')]), MovieInfo(title='86. Tuilte', url='https://www.imdb.com/title/tt36331303/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Órfhlaith Ní Chearnaigh', url='https://www.imdb.com/name/nm8101719/')], thespians=[Thespian(name='Órfhlaith Ní Chearnaigh', url='https://www.imdb.com/name/nm8101719/')]), MovieInfo(title='87. UNDERDROGS: a League of Ireland Story', url='https://www.imdb.com/title/tt30629158/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Conor McGuinness', url='https://www.imdb.com/name/nm15517561/'), Thespian(name='Sean Mathews', url='https://www.imdb.com/name/nm15648136/')]), MovieInfo(title='88. The Keepers', url='https://www.imdb.com/title/tt35716318/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Eoin McGowan', url='https://www.imdb.com/name/nm6536263/')]), MovieInfo(title='89. Pikmin Destruction', url='https://www.imdb.com/title/tt32769006/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Cílan Barrett', url='https://www.imdb.com/name/nm15811959/'), Director(name='Cameron Martin', url='https://www.imdb.com/name/nm15811958/')], thespians=[Thespian(name='Cameron Martin', url='https://www.imdb.com/name/nm15811958/')]), MovieInfo(title='90. Once Upon a Lockdown', url='https://www.imdb.com/title/tt32576661/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Aidan Killian', url='https://www.imdb.com/name/nm16246023/')]), MovieInfo(title='91. Admonition', url='https://www.imdb.com/title/tt30789930/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Luke Spellacy Shaw', url='https://www.imdb.com/name/nm11023043/')], thespians=[Thespian(name='Luke Spellacy Shaw', url='https://www.imdb.com/name/nm11023043/')]), MovieInfo(title='92. Cold Brew', url='https://www.imdb.com/title/tt34178805/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Cian Salmon', url='https://www.imdb.com/name/nm14003239/')]), MovieInfo(title='93. The Rent Strike', url='https://www.imdb.com/title/tt34570680/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Declan Mallon', url='https://www.imdb.com/name/nm16721939/'), Thespian(name=\"Azzy O'Connor\", url='https://www.imdb.com/name/nm16721940/'), Thespian(name='Fiadh Tubridy', url='https://www.imdb.com/name/nm16721938/')]), MovieInfo(title='94. Douglas Stories', url='https://www.imdb.com/title/tt34973297/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Emma Bowell', url='https://www.imdb.com/name/nm12989765/')]), MovieInfo(title='95. World of Sathvik and his friends : The Cursed Pumpkin', url='https://www.imdb.com/title/tt34351044/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Naveen Maremanda', url='https://www.imdb.com/name/nm16505890/'), Director(name='Vishnu Priya Matham', url='https://www.imdb.com/name/nm16668015/')], thespians=[Thespian(name='Naveen Maremanda', url='https://www.imdb.com/name/nm16505890/')]), MovieInfo(title='96. Envy', url='https://www.imdb.com/title/tt31522649/', imdbRating=None, imdbVotes=None, metascore=None, directors=[], thespians=[Thespian(name='Tony McCleane Fay', url='https://www.imdb.com/name/nm15878943/')]), MovieInfo(title='97. 95B', url='https://www.imdb.com/title/tt35309410/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Michael Higgins', url='https://www.imdb.com/name/nm2822843/')], thespians=[Thespian(name='Michael Higgins', url='https://www.imdb.com/name/nm2822843/')]), MovieInfo(title='98. TIN - Time Lord Society 10 Year Anniversary', url='https://www.imdb.com/title/tt32209960/', imdbRating=None, imdbVotes=None, metascore=None, directors=[Director(name='Dean McDevitt', url='https://www.imdb.com/name/nm15265952/'), Director(name='Elizabeth Sorrell', url='https://www.imdb.com/name/nm16074699/')], thespians=[Thespian(name='Dean McDevitt', url='https://www.imdb.com/name/nm15265952/')])]\n"
     ]
    }
   ],
   "source": [
    "print(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702fd560-578f-47d6-8ec8-c0e374eb0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv\n",
    "\n",
    "# Generic entity saver/loader functions\n",
    "def saveEntityListAsJSON(entities: List, filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump([asdict(e) for e in entities], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def saveEntityListAsCSV(entities: List, filename: str):\n",
    "    if not entities:\n",
    "        return\n",
    "    with open(filename, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=asdict(entities[0]).keys())\n",
    "        writer.writeheader()\n",
    "        for e in entities:\n",
    "            writer.writerow(asdict(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850fcfa-773f-4b8d-8398-99058cc8d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saveEntityListAsJSON(movies, 'movies.json')\n",
    "saveEntityListAsCSV(movies, 'movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389687da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping movies from IMDb...\n",
      "Enriching with credits and financial data, and academy awards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [17:54<00:00, 17.90s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Scraped 60 movies with their financial data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, List\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "\n",
    "httpHeaders = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.imdb.com/\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "}\n",
    "# Changed from ES (Spain) to US (United States)\n",
    "url = 'https://www.imdb.com/search/title/?title_type=tv_movie,feature&release_date=2024-01-01,2024-12-31&country_of_origin=US&moviemeter=1,1000'\n",
    "\n",
    "@dataclass\n",
    "class Director:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class Thespian:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class MovieInfo:\n",
    "    title: str\n",
    "    url: str\n",
    "    imdbRating: Optional[float] = None\n",
    "    imdbVotes: Optional[int] = None\n",
    "    metascore: Optional[int] = None\n",
    "    budget: Optional[str] = None\n",
    "    domesticGross: Optional[str] = None\n",
    "    worldwideGross: Optional[str] = None\n",
    "    academyAwards: List[str] = field(default_factory=list)\n",
    "    directors: List[Director] = field(default_factory=list)\n",
    "    thespians: List[Thespian] = field(default_factory=list)\n",
    "\n",
    "# Generic logger\n",
    "def logEvent(msg: str, level: str = \"INFO\", filePath: str = \"scrapingLog.log\") -> None:\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "    for line in msg.strip().splitlines():\n",
    "        with open(filePath, 'a') as f:\n",
    "            f.write(f\"{timestamp} [{level}] {line}\\n\")\n",
    "\n",
    "# Error logger shortcut\n",
    "def logError(msg: str, filePath: str = \"scrapingErrors.log\") -> None:\n",
    "    logEvent(msg, level=\"ERROR\", filePath=filePath)\n",
    "\n",
    "# Universal try-catcher with controllable flow\n",
    "def trierCatcher(keepGoing, traceMsg, task, *taskArgs, **taskKwargs):\n",
    "    if not keepGoing:\n",
    "        return (False, None)\n",
    "    try:\n",
    "        result = task(*taskArgs, **taskKwargs)\n",
    "        return (True, result)\n",
    "    except Exception as e:\n",
    "        logError(f\"{traceMsg}\\n{repr(e)}\")\n",
    "        return (False, None)\n",
    "\n",
    "# Extract movie info from current loaded page\n",
    "def tryParseMovieItem(item) -> Optional[MovieInfo]:\n",
    "    try:\n",
    "        titleBlock = item.select_one(\"div.dli-parent h3\")\n",
    "        if not titleBlock:\n",
    "            return None\n",
    "        title = titleBlock.text.strip()\n",
    "        anchor = item.select_one(\"a\")\n",
    "        if not anchor:\n",
    "            return None\n",
    "        url = \"https://www.imdb.com\" + anchor['href'].split('?')[0]\n",
    "\n",
    "        imdbRatingSpan = item.select_one(\"span.ipc-rating-star--rating\")\n",
    "        imdbVotesSpan = item.select_one(\"span.ipc-rating-star--voteCount\")\n",
    "        metascoreSpan = item.select_one(\"span.metacritic-score-box\")\n",
    "\n",
    "        imdbRating = imdbRatingSpan.text if imdbRatingSpan else None\n",
    "        imdbVotes = imdbVotesSpan.text if imdbVotesSpan else None\n",
    "        metascore = metascoreSpan.text if metascoreSpan else None\n",
    "\n",
    "        return MovieInfo(title=title, url=url, imdbRating=imdbRating, imdbVotes=imdbVotes, metascore=metascore)\n",
    "    except Exception as e:\n",
    "        logError(f\"Error parsing a movie item: {repr(e)}\")\n",
    "        return None\n",
    "\n",
    "def extractMoviesFromPage(pageSource: str) -> List[MovieInfo]:\n",
    "    soup = BeautifulSoup(pageSource, 'html.parser')\n",
    "    movieItems = soup.select(\"ul.ipc-metadata-list > li\")\n",
    "    movieBatch = []\n",
    "    for item in movieItems:\n",
    "        if len(item.attrs) == 1:\n",
    "            movie = tryParseMovieItem(item)\n",
    "            if movie:\n",
    "                movieBatch.append(movie)\n",
    "    return movieBatch\n",
    "\n",
    "def getBrowser(someURL):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(someURL)\n",
    "    return driver \n",
    "\n",
    "def scrapeIMDbMoviesWithSlidingWindow(someURL: str) -> List[MovieInfo]:\n",
    "    movieList = []\n",
    "    batchCounter = 0\n",
    "    defaultBatchSize = 50\n",
    "    pageBatchSize = 50\n",
    "    sleepTimeSeconds = 0.5\n",
    "    driverWaitTimeout = 10\n",
    "    keepGoing = True\n",
    "    nMoreButtonText = \"ipc-see-more__button\"\n",
    "    buttonTextRetrievalJSCommand = \"return arguments[0].innerText;\"\n",
    "    domPruningJSCommand = \"\"\"\n",
    "            const ul = document.querySelector(\"ul.ipc-metadata-list\");\n",
    "            const lis = ul.querySelectorAll(\"li\");\n",
    "            for (let i = 0; i < 50 && i < lis.length; i++) { lis[i].remove(); }\n",
    "        \"\"\"\n",
    "    clicketyJSCommand = \"arguments[0].click();\"\n",
    "    scrollJSCommand = \"arguments[0].scrollIntoView({block: 'center'});\"\n",
    "    metadataList = \"ipc-metadata-list-summary-item\"\n",
    "    pruningFailMsg = \"JS movie LI cleanup failure\"\n",
    "    movieExtractionFailMsg = \"Failed to extract movies from page\"\n",
    "    movieExtensionFailMsg = \"Failed to append new movies\"\n",
    "    clickFailMsg = \"Clickety failure\"\n",
    "    loadFailMsg = \"New movie load wait failure\"\n",
    "    scrollFailMsg = \"Scroll failure\"\n",
    "    batchSizeFailMsg = \"Batch size update failure\"\n",
    "    sleepFailMsg = \"Sleep failure\"\n",
    "    buttonFailMsg = \"Button retrieval failure\"\n",
    "    buttonTextFailMsg = \"Button text fetch failure\"\n",
    "    driver = getBrowser(someURL)\n",
    "\n",
    "    while keepGoing:\n",
    "        keepGoing, newMovies = trierCatcher(keepGoing, movieExtractionFailMsg, extractMoviesFromPage, driver.page_source)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, movieExtensionFailMsg, movieList.extend, newMovies)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, pruningFailMsg, driver.execute_script, domPruningJSCommand)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, button = trierCatcher(keepGoing, buttonFailMsg, WebDriverWait(driver, driverWaitTimeout).until, EC.element_to_be_clickable((By.CLASS_NAME, nMoreButtonText)))\n",
    "        keepGoing, buttonText = trierCatcher(keepGoing, buttonTextFailMsg, driver.execute_script, buttonTextRetrievalJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, scrollFailMsg, driver.execute_script, scrollJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, clickFailMsg, driver.execute_script, clicketyJSCommand, button)\n",
    "        keepGoing, match = trierCatcher(keepGoing, batchSizeFailMsg, re.search, r\"(\\d+)\", buttonText)\n",
    "        pageBatchSize = int(match.group(1)) if keepGoing and match else defaultBatchSize\n",
    "        keepGoing, _ = trierCatcher(keepGoing, loadFailMsg, WebDriverWait(driver, driverWaitTimeout).until, lambda d: len(d.find_elements(By.CLASS_NAME, metadataList)) >= pageBatchSize)\n",
    "    driver.quit()\n",
    "    return movieList\n",
    "\n",
    "def scrapeMovieCredits(movieURL: str) -> tuple[List[Director], List[Thespian]]:\n",
    "    fullCreditsURL = movieURL + \"fullcredits/\"\n",
    "    directors = []\n",
    "    thespians = []\n",
    "    try:\n",
    "        response = requests.get(fullCreditsURL, headers=httpHeaders)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve full credits page for {movieURL}\\n{repr(e)}\")\n",
    "        return (directors, thespians)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # --- DIRECTORS ---\n",
    "    try:\n",
    "        director_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-director\"})\n",
    "        if director_section:\n",
    "            ul = director_section.find(\"ul\")\n",
    "            if ul:\n",
    "                for li in ul.find_all(\"li\", recursive=False):\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        directors.append(Director(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing directors for {movieURL}\\n{repr(e)}\")\n",
    "        \n",
    "    # --- CAST (limited to top 5) ---\n",
    "    try:\n",
    "        cast_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-cast\"})\n",
    "        if cast_section:\n",
    "            ul = cast_section.find(\"ul\")\n",
    "            if ul:\n",
    "                cast_lis = ul.find_all(\"li\", class_=\"full-credits-page-list-item\", recursive=False)[:5]\n",
    "                for li in cast_lis:\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        thespians.append(Thespian(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing cast for {movieURL}\\n{repr(e)}\")\n",
    "\n",
    "    return (directors, thespians)\n",
    "\n",
    "def cleanMovieTitle(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean movie title by removing:\n",
    "    1. Ranking number prefix (e.g., \"1. \", \"25. \")\n",
    "    2. Year in parentheses (e.g., \"(2024)\")\n",
    "    \"\"\"\n",
    "    # Remove ranking number prefix (e.g., \"1. \", \"25. \")\n",
    "    cleaned_title = re.sub(r'^\\d+\\.\\s*', '', title)\n",
    "    \n",
    "    # Remove year in parentheses\n",
    "    cleaned_title = re.sub(r'\\s*\\(\\d{4}\\)\\s*', '', cleaned_title)\n",
    "    \n",
    "    return cleaned_title.strip()\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove accents from characters (e.g. à -> a, ñ -> n)\n",
    "    \"\"\"\n",
    "    normalized = unicodedata.normalize('NFD', text)\n",
    "    return ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def formatMovieTitleForTheNumbers(title: str, year: str = \"2024\") -> str:\n",
    "    \"\"\"\n",
    "    Format a movie title for use in The Numbers, respecting their naming style.\n",
    "    Handles special characters, & → and, # → Number, and places articles correctly.\n",
    "    \"\"\"\n",
    "    title = cleanMovieTitle(title)\n",
    "    title = title.replace('&', 'and').replace('#', 'Number')\n",
    "    title = re.sub(r'[^\\w\\s:-]', '', title)\n",
    "    title = remove_accents(title)\n",
    "\n",
    "    # Split around colon if present\n",
    "    parts = title.split(':')\n",
    "    if len(parts) == 2:\n",
    "        main, subtitle = parts[0].strip(), parts[1].strip()\n",
    "\n",
    "        # Check if main part starts with article\n",
    "        words = main.split()\n",
    "        articles = []\n",
    "        if words and words[0].lower() in ['the', 'a', 'an']:\n",
    "            articles.append(words.pop(0))  # remove and store\n",
    "\n",
    "        # Recombine all parts\n",
    "        final_words = words + articles + subtitle.split()\n",
    "    else:\n",
    "        # No colon, just do standard cleaning\n",
    "        final_words = title.split()\n",
    "\n",
    "        # Move any articles to the end (fallback behavior)\n",
    "        articles = [w for w in final_words if w.lower() in ['the', 'a', 'an']]\n",
    "        final_words = [w for w in final_words if w.lower() not in ['the', 'a', 'an']] + articles\n",
    "\n",
    "    formatted_title = '-'.join(final_words) + f\"-({year})\"\n",
    "    formatted_title = re.sub(r'-+', '-', formatted_title)\n",
    "    return formatted_title\n",
    "\n",
    "from typing import Optional\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def getBoxOfficeDataFromTheNumbers(movie_title: str, year: str = \"2024\") -> tuple[Optional[str], Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Extract budget and box office data from The Numbers.\n",
    "    Returns (budget, domestic_gross, worldwide_gross)\n",
    "    \"\"\"\n",
    "    budget = None\n",
    "    domestic_gross = None\n",
    "    worldwide_gross = None\n",
    "    \n",
    "    if not movie_title:\n",
    "        return budget, domestic_gross, worldwide_gross\n",
    "    \n",
    "    formatted_title = formatMovieTitleForTheNumbers(movie_title, year)\n",
    "    thenumbers_url = f\"https://www.the-numbers.com/movie/{formatted_title}#tab=summary\"\n",
    "    \n",
    "    try:\n",
    "        logEvent(f\"Accessing URL: {thenumbers_url}\")\n",
    "        response = requests.get(thenumbers_url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # ✅ Buscar el presupuesto de forma precisa\n",
    "        summary_div = soup.find(\"div\", id=\"summary\")\n",
    "        if summary_div:\n",
    "            budget_row = summary_div.find(\"b\", string=re.compile(r\"Production(\\xa0| )Budget:\"))\n",
    "            if budget_row:\n",
    "                td = budget_row.find_next(\"td\")\n",
    "                if td:\n",
    "                    # Solo extraemos el número (ej. \"$6,000,000\")\n",
    "                    match = re.search(r\"\\$\\d[\\d,]*\", td.text)\n",
    "                    if match:\n",
    "                        budget = match.group(0).strip()\n",
    "\n",
    "        # Buscar la tabla con los ingresos (igual que antes)\n",
    "        tables = soup.find_all(\"table\")\n",
    "        for table in tables:\n",
    "            # Domestic Box Office\n",
    "            domestic_element = table.find(string=re.compile(\"Domestic Box Office\", re.IGNORECASE))\n",
    "            if domestic_element:\n",
    "                row = domestic_element.find_parent(\"tr\")\n",
    "                if row:\n",
    "                    data_cells = row.find_all(\"td\", class_=\"data\")\n",
    "                    if data_cells:\n",
    "                        domestic_gross = data_cells[0].text.strip()\n",
    "            \n",
    "            # Worldwide Box Office\n",
    "            worldwide_element = table.find(string=re.compile(\"Worldwide Box Office\", re.IGNORECASE))\n",
    "            if worldwide_element:\n",
    "                row = worldwide_element.find_parent(\"tr\")\n",
    "                if row:\n",
    "                    data_cells = row.find_all(\"td\", class_=\"data\")\n",
    "                    if data_cells:\n",
    "                        worldwide_gross = data_cells[0].text.strip()\n",
    "        \n",
    "        logEvent(f\"Retrieved data for {movie_title}: Budget={budget}, Domestic={domestic_gross}, Worldwide={worldwide_gross}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve box office data from The Numbers for {movie_title}\\n{repr(e)}\")\n",
    "    \n",
    "    return budget, domestic_gross, worldwide_gross\n",
    "\n",
    "def scrapeAcademyAwards(movieURL: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Ultra specific function targeting the exact HTML structure shown in screenshots.\n",
    "    \"\"\"\n",
    "    awardsURL = movieURL + \"awards/\"\n",
    "    awards = []\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(awardsURL, headers=httpHeaders)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve awards page for {movieURL}\\n{repr(e)}\")\n",
    "        return awards\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        # Buscar específicamente la sección con atributo data-testid=\"sub-section-ev0000003\"\n",
    "        # ya que \"ev0000003\" parece ser el código de los Academy Awards en IMDB\n",
    "        academy_section = soup.find(\"div\", attrs={\"data-testid\": lambda v: v and \"sub-section-ev0000003\" in v})\n",
    "        \n",
    "        if not academy_section:\n",
    "            # Si no encuentra con el ID específico, buscar por el texto\n",
    "            academy_spans = soup.find_all(\"span\", string=lambda s: s and \"Academy Awards, USA\" in s)\n",
    "            for span in academy_spans:\n",
    "                section = span.find_parent(\"div\", attrs={\"data-testid\": lambda v: v and \"sub-section\" in v})\n",
    "                if section:\n",
    "                    academy_section = section\n",
    "                    break\n",
    "        \n",
    "        if academy_section:\n",
    "            # Buscar todos los items de la lista de premios\n",
    "            award_items = academy_section.find_all(\"li\", class_=\"ipc-metadata-list-summary-item\")\n",
    "            \n",
    "            if not award_items:\n",
    "                # Si no encuentra con ese selector, buscar con uno más general\n",
    "                award_items = academy_section.find_all(\"div\", class_=lambda c: c and \"ipc-metadata-list-summary-item\" in c)\n",
    "            \n",
    "            for item in award_items:\n",
    "                # Buscar el texto que indica si es ganador\n",
    "                if \"Ganador\" not in item.text and \"Winner\" not in item.text:\n",
    "                    continue\n",
    "                \n",
    "                # Buscar la categoría del premio\n",
    "                # Primero buscar spans con clase específica para categorías\n",
    "                category_span = item.find(\"span\", class_=lambda c: c and \"awardCategoryName\" in c)\n",
    "                \n",
    "                if category_span:\n",
    "                    category = category_span.text.strip()\n",
    "                    awards.append(category)\n",
    "                else:\n",
    "                    # Buscar en elementos li dentro de listas inline\n",
    "                    category_li = item.find(\"li\", class_=\"ipc-inline-list__item\")\n",
    "                    if category_li:\n",
    "                        # Buscar span dentro del li\n",
    "                        category_span = category_li.find(\"span\")\n",
    "                        if category_span and \"Best\" in category_span.text:\n",
    "                            category = category_span.text.strip()\n",
    "                            awards.append(category)\n",
    "        \n",
    "        # Registrar resultados para depuración\n",
    "        if awards:\n",
    "            logEvent(f\"Found {len(awards)} awards: {awards}\")\n",
    "        else:\n",
    "            logEvent(\"No awards found using ultra specific method\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logError(f\"Error in ultra specific scraper: {repr(e)}\")\n",
    "        \n",
    "    # Si no encontramos nada, guardar HTML para análisis\n",
    "    if not awards:\n",
    "        try:\n",
    "            with open(\"imdb_awards_debug.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(soup.prettify())\n",
    "            logEvent(\"Saved HTML to imdb_awards_debug.html for debugging\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return awards\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    # Get list of movies from IMDb\n",
    "    print(\"Scraping movies from IMDb...\")\n",
    "    movies = scrapeIMDbMoviesWithSlidingWindow(url)\n",
    "    \n",
    "    # Enrich with credits and financial data\n",
    "    print(\"Enriching with credits and financial data, and academy awards...\")\n",
    "    for movie in tqdm(movies):\n",
    "        # Get credits\n",
    "        directors, thespians = scrapeMovieCredits(movie.url)\n",
    "        movie.directors = directors\n",
    "        movie.thespians = thespians\n",
    "        \n",
    "        # Get financial data from The Numbers\n",
    "        # Extract movie title and try to determine year\n",
    "        title = movie.title\n",
    "        year_match = re.search(r\"\\((\\d{4})\\)\", title)\n",
    "        year = year_match.group(1) if year_match else \"2024\"\n",
    "        \n",
    "        budget, domestic, worldwide = getBoxOfficeDataFromTheNumbers(title, year)\n",
    "        movie.budget = budget\n",
    "        movie.domesticGross = domestic\n",
    "        movie.worldwideGross = worldwide\n",
    "        \n",
    "        awards = scrapeAcademyAwards(movie.url)\n",
    "        movie.academyAwards = awards\n",
    "        # Respect the website's rate limits\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Save data\n",
    "    saveEntityListAsJSON(movies, 'movies.json')\n",
    "    saveEntityListAsCSV(movies, 'movies.csv')\n",
    "    print(f\"Done! Scraped {len(movies)} movies with their financial data.\")\n",
    "\n",
    "# Generic entity saver/loader functions\n",
    "def saveEntityListAsJSON(entities: List, filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump([asdict(e) for e in entities], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def saveEntityListAsCSV(entities: List, filename: str):\n",
    "    if not entities:\n",
    "        return\n",
    "    with open(filename, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=asdict(entities[0]).keys())\n",
    "\n",
    "        writer.writeheader()\n",
    "        for e in entities:\n",
    "            writer.writerow(asdict(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9099a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping movies from United States...\n",
      "Found 807 movies from United States\n",
      "Enriching with credits, financial data, and Academy Awards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 807/807 [3:09:33<00:00, 14.09s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing between countries...\n",
      "Scraping movies from United Kingdom...\n",
      "Found 163 movies from United Kingdom\n",
      "Enriching with credits, financial data, and BAFTA Film Awards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [38:42<00:00, 14.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pausing between countries...\n",
      "Scraping movies from Spain...\n",
      "Found 44 movies from Spain\n",
      "Enriching with credits, financial data, and Goya Awards...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44/44 [10:35<00:00, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Scraped 1014 movies from all countries with their data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, List, Dict, Tuple, Literal\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "import unicodedata\n",
    "\n",
    "# Constantes para cada país\n",
    "COUNTRIES = {\n",
    "        \"US\": {\n",
    "        \"code\": \"US\",\n",
    "        \"name\": \"United States\",\n",
    "        \"award_name\": \"Academy Awards\",\n",
    "        \"award_id\": \"ev0000003\",\n",
    "        \"url\": \"https://www.imdb.com/search/title/?title_type=tv_movie,feature&release_date=2023-01-01,2024-12-31&country_of_origin=US&moviemeter=1,20000\"\n",
    "    },\n",
    "    \"GB\": {\n",
    "        \"code\": \"GB\",\n",
    "        \"name\": \"United Kingdom\",\n",
    "        \"award_name\": \"BAFTA Film Awards\",\n",
    "        \"award_id\": \"ev0000123\",\n",
    "        \"url\": \"https://www.imdb.com/search/title/?title_type=tv_movie,feature&release_date=2023-01-01,2024-12-31&country_of_origin=GB&moviemeter=1,20000\"\n",
    "    },\n",
    "    \"ES\": {\n",
    "        \"code\": \"ES\",\n",
    "        \"name\": \"Spain\",\n",
    "        \"award_name\": \"Goya Awards\",\n",
    "        \"award_id\": \"ev0000299\",\n",
    "        \"url\": \"https://www.imdb.com/es-es/search/title/?title_type=tv_movie,feature&release_date=2023-01-01,2024-12-31&country_of_origin=ES&moviemeter=1,20000\"\n",
    "    }\n",
    "}\n",
    "\n",
    "httpHeaders = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Referer\": \"https://www.imdb.com/\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Upgrade-Insecure-Requests\": \"1\",\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class Director:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class Thespian:\n",
    "    name: str\n",
    "    url: str\n",
    "\n",
    "@dataclass\n",
    "class MovieInfo:\n",
    "    title: str\n",
    "    url: str\n",
    "    country: str = \"\"  # Añadido campo de país\n",
    "    imdbRating: Optional[float] = None\n",
    "    imdbVotes: Optional[int] = None\n",
    "    metascore: Optional[int] = None\n",
    "    budget: Optional[str] = None\n",
    "    domesticGross: Optional[str] = None\n",
    "    worldwideGross: Optional[str] = None\n",
    "    awards: List[str] = field(default_factory=list)  # Renombrado para ser genérico (no solo Academy Awards)\n",
    "    directors: List[Director] = field(default_factory=list)\n",
    "    thespians: List[Thespian] = field(default_factory=list)\n",
    "\n",
    "# Generic logger\n",
    "def logEvent(msg: str, level: str = \"INFO\", filePath: str = \"scrapingLog.log\") -> None:\n",
    "    timestamp = datetime.now().strftime(\"[%Y-%m-%d %H:%M:%S]\")\n",
    "    for line in msg.strip().splitlines():\n",
    "        with open(filePath, 'a') as f:\n",
    "            f.write(f\"{timestamp} [{level}] {line}\\n\")\n",
    "\n",
    "# Error logger shortcut\n",
    "def logError(msg: str, filePath: str = \"scrapingErrors.log\") -> None:\n",
    "    logEvent(msg, level=\"ERROR\", filePath=filePath)\n",
    "\n",
    "# Universal try-catcher with controllable flow\n",
    "def trierCatcher(keepGoing, traceMsg, task, *taskArgs, **taskKwargs):\n",
    "    if not keepGoing:\n",
    "        return (False, None)\n",
    "    try:\n",
    "        result = task(*taskArgs, **taskKwargs)\n",
    "        return (True, result)\n",
    "    except Exception as e:\n",
    "        logError(f\"{traceMsg}\\n{repr(e)}\")\n",
    "        return (False, None)\n",
    "\n",
    "# Extract movie info from current loaded page\n",
    "def tryParseMovieItem(item, country_code: str) -> Optional[MovieInfo]:\n",
    "    try:\n",
    "        titleBlock = item.select_one(\"div.dli-parent h3\")\n",
    "        if not titleBlock:\n",
    "            return None\n",
    "        title = titleBlock.text.strip()\n",
    "        anchor = item.select_one(\"a\")\n",
    "        if not anchor:\n",
    "            return None\n",
    "        url = \"https://www.imdb.com\" + anchor['href'].split('?')[0]\n",
    "\n",
    "        imdbRatingSpan = item.select_one(\"span.ipc-rating-star--rating\")\n",
    "        imdbVotesSpan = item.select_one(\"span.ipc-rating-star--voteCount\")\n",
    "        metascoreSpan = item.select_one(\"span.metacritic-score-box\")\n",
    "\n",
    "        imdbRating = imdbRatingSpan.text if imdbRatingSpan else None\n",
    "        imdbVotes = imdbVotesSpan.text if imdbVotesSpan else None\n",
    "        metascore = metascoreSpan.text if metascoreSpan else None\n",
    "\n",
    "        return MovieInfo(title=title, url=url, country=country_code, imdbRating=imdbRating, \n",
    "                         imdbVotes=imdbVotes, metascore=metascore)\n",
    "    except Exception as e:\n",
    "        logError(f\"Error parsing a movie item: {repr(e)}\")\n",
    "        return None\n",
    "\n",
    "def extractMoviesFromPage(pageSource: str, country_code: str) -> List[MovieInfo]:\n",
    "    soup = BeautifulSoup(pageSource, 'html.parser')\n",
    "    movieItems = soup.select(\"ul.ipc-metadata-list > li\")\n",
    "    movieBatch = []\n",
    "    for item in movieItems:\n",
    "        if len(item.attrs) == 1:\n",
    "            movie = tryParseMovieItem(item, country_code)\n",
    "            if movie:\n",
    "                movieBatch.append(movie)\n",
    "    return movieBatch\n",
    "\n",
    "def getBrowser(someURL):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--lang=en-US\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(someURL)\n",
    "    return driver \n",
    "\n",
    "def scrapeIMDbMoviesWithSlidingWindow(country_info: Dict) -> List[MovieInfo]:\n",
    "    someURL = country_info[\"url\"]\n",
    "    country_code = country_info[\"code\"]\n",
    "    movieList = []\n",
    "    batchCounter = 0\n",
    "    defaultBatchSize = 50\n",
    "    pageBatchSize = 50\n",
    "    sleepTimeSeconds = 0.5\n",
    "    driverWaitTimeout = 10\n",
    "    keepGoing = True\n",
    "    nMoreButtonText = \"ipc-see-more__button\"\n",
    "    buttonTextRetrievalJSCommand = \"return arguments[0].innerText;\"\n",
    "    domPruningJSCommand = \"\"\"\n",
    "            const ul = document.querySelector(\"ul.ipc-metadata-list\");\n",
    "            const lis = ul.querySelectorAll(\"li\");\n",
    "            for (let i = 0; i < 50 && i < lis.length; i++) { lis[i].remove(); }\n",
    "        \"\"\"\n",
    "    clicketyJSCommand = \"arguments[0].click();\"\n",
    "    scrollJSCommand = \"arguments[0].scrollIntoView({block: 'center'});\"\n",
    "    metadataList = \"ipc-metadata-list-summary-item\"\n",
    "    pruningFailMsg = \"JS movie LI cleanup failure\"\n",
    "    movieExtractionFailMsg = \"Failed to extract movies from page\"\n",
    "    movieExtensionFailMsg = \"Failed to append new movies\"\n",
    "    clickFailMsg = \"Clickety failure\"\n",
    "    loadFailMsg = \"New movie load wait failure\"\n",
    "    scrollFailMsg = \"Scroll failure\"\n",
    "    batchSizeFailMsg = \"Batch size update failure\"\n",
    "    sleepFailMsg = \"Sleep failure\"\n",
    "    buttonFailMsg = \"Button retrieval failure\"\n",
    "    buttonTextFailMsg = \"Button text fetch failure\"\n",
    "    driver = getBrowser(someURL)\n",
    "\n",
    "    while keepGoing:\n",
    "        keepGoing, newMovies = trierCatcher(keepGoing, movieExtractionFailMsg, extractMoviesFromPage, driver.page_source, country_code)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, movieExtensionFailMsg, movieList.extend, newMovies)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, pruningFailMsg, driver.execute_script, domPruningJSCommand)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        \n",
    "        # Verificar si hay botón de \"Ver más\" o si estamos al final\n",
    "        try:\n",
    "            button = WebDriverWait(driver, driverWaitTimeout).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, nMoreButtonText))\n",
    "            )\n",
    "        except:\n",
    "            # Si no hay botón de \"Ver más\", terminamos\n",
    "            logEvent(f\"No more movies to load for {country_code}, ending scraping\")\n",
    "            break\n",
    "            \n",
    "        keepGoing, buttonText = trierCatcher(keepGoing, buttonTextFailMsg, driver.execute_script, buttonTextRetrievalJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, scrollFailMsg, driver.execute_script, scrollJSCommand, button)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, sleepFailMsg, time.sleep, sleepTimeSeconds)\n",
    "        keepGoing, _ = trierCatcher(keepGoing, clickFailMsg, driver.execute_script, clicketyJSCommand, button)\n",
    "        keepGoing, match = trierCatcher(keepGoing, batchSizeFailMsg, re.search, r\"(\\d+)\", buttonText)\n",
    "        pageBatchSize = int(match.group(1)) if keepGoing and match else defaultBatchSize\n",
    "        keepGoing, _ = trierCatcher(keepGoing, loadFailMsg, WebDriverWait(driver, driverWaitTimeout).until, lambda d: len(d.find_elements(By.CLASS_NAME, metadataList)) >= pageBatchSize)\n",
    "    driver.quit()\n",
    "    return movieList\n",
    "\n",
    "def scrapeMovieCredits(movieURL: str) -> tuple[List[Director], List[Thespian]]:\n",
    "    fullCreditsURL = movieURL + \"fullcredits/\"\n",
    "    directors = []\n",
    "    thespians = []\n",
    "    try:\n",
    "        response = requests.get(fullCreditsURL, headers=httpHeaders)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve full credits page for {movieURL}\\n{repr(e)}\")\n",
    "        return (directors, thespians)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # --- DIRECTORS ---\n",
    "    try:\n",
    "        director_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-director\"})\n",
    "        if director_section:\n",
    "            ul = director_section.find(\"ul\")\n",
    "            if ul:\n",
    "                for li in ul.find_all(\"li\", recursive=False):\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        directors.append(Director(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing directors for {movieURL}\\n{repr(e)}\")\n",
    "        \n",
    "    # --- CAST (limited to top 5) ---\n",
    "    try:\n",
    "        cast_section = soup.find(\"div\", attrs={\"data-testid\": \"sub-section-cast\"})\n",
    "        if cast_section:\n",
    "            ul = cast_section.find(\"ul\")\n",
    "            if ul:\n",
    "                cast_lis = ul.find_all(\"li\", class_=\"full-credits-page-list-item\", recursive=False)[:5]\n",
    "                for li in cast_lis:\n",
    "                    anchor = li.find(\"a\", class_=\"name-credits--title-text-big\")\n",
    "                    if anchor:\n",
    "                        name = anchor.text.strip()\n",
    "                        url = \"https://www.imdb.com\" + anchor[\"href\"].split(\"?\")[0]\n",
    "                        thespians.append(Thespian(name=name, url=url))\n",
    "    except Exception as e:\n",
    "        logError(f\"Failed parsing cast for {movieURL}\\n{repr(e)}\")\n",
    "\n",
    "    return (directors, thespians)\n",
    "\n",
    "def cleanMovieTitle(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean movie title by removing:\n",
    "    1. Ranking number prefix (e.g., \"1. \", \"25. \")\n",
    "    2. Year in parentheses (e.g., \"(2024)\")\n",
    "    \"\"\"\n",
    "    # Remove ranking number prefix (e.g., \"1. \", \"25. \")\n",
    "    cleaned_title = re.sub(r'^\\d+\\.\\s*', '', title)\n",
    "    \n",
    "    # Remove year in parentheses\n",
    "    cleaned_title = re.sub(r'\\s*\\(\\d{4}\\)\\s*', '', cleaned_title)\n",
    "    \n",
    "    return cleaned_title.strip()\n",
    "\n",
    "def remove_accents(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove accents from characters (e.g. à -> a, ñ -> n)\n",
    "    \"\"\"\n",
    "    normalized = unicodedata.normalize('NFD', text)\n",
    "    return ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def formatMovieTitleForTheNumbers(title: str, year: str = \"2024\") -> str:\n",
    "    \"\"\"\n",
    "    Format a movie title for use in The Numbers, respecting their naming style.\n",
    "    Handles special characters, & → and, # → Number, and places articles correctly.\n",
    "    \"\"\"\n",
    "    title = cleanMovieTitle(title)\n",
    "    title = title.replace('&', 'and')\n",
    "    title = title.replace('#', 'Number')\n",
    "    title = re.sub(r'[^\\w\\s:-]', '', title)\n",
    "    title = remove_accents(title)\n",
    "\n",
    "    # Split around colon if present\n",
    "    parts = title.split(':')\n",
    "    if len(parts) == 2:\n",
    "        main, subtitle = parts[0].strip(), parts[1].strip()\n",
    "\n",
    "        # Check if main part starts with article\n",
    "        words = main.split()\n",
    "        articles = []\n",
    "        if words and words[0].lower() in ['the', 'a', 'an', 'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas']:\n",
    "            articles.append(words.pop(0))  # remove and store\n",
    "\n",
    "        # Recombine all parts\n",
    "        final_words = words + articles + subtitle.split()\n",
    "    else:\n",
    "        # No colon, just do standard cleaning\n",
    "        final_words = title.split()\n",
    "\n",
    "        # Move any articles to the end (fallback behavior)\n",
    "        articles = [w for w in final_words if w.lower() in ['the', 'a', 'an', 'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas']]\n",
    "        final_words = [w for w in final_words if w.lower() not in ['the', 'a', 'an', 'el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas']] + articles\n",
    "\n",
    "    formatted_title = '-'.join(final_words) + f\"-({year})\"\n",
    "    formatted_title = re.sub(r'-+', '-', formatted_title)\n",
    "    return formatted_title\n",
    "\n",
    "def getBoxOfficeDataFromTheNumbers(movie_title: str, country_code: str, year: str = \"2024\") -> tuple[Optional[str], Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Extract budget and box office data from The Numbers.\n",
    "    Returns (budget, domestic_gross, worldwide_gross)\n",
    "    \"\"\"\n",
    "    budget = None\n",
    "    domestic_gross = None\n",
    "    worldwide_gross = None\n",
    "    \n",
    "    if not movie_title:\n",
    "        return budget, domestic_gross, worldwide_gross\n",
    "    \n",
    "    formatted_title = formatMovieTitleForTheNumbers(movie_title, year)\n",
    "    thenumbers_url = f\"https://www.the-numbers.com/movie/{formatted_title}#tab=summary\"\n",
    "    \n",
    "    try:\n",
    "        logEvent(f\"Accessing URL for {country_code} movie: {thenumbers_url}\")\n",
    "        response = requests.get(thenumbers_url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Buscar el presupuesto de forma precisa\n",
    "        summary_div = soup.find(\"div\", id=\"summary\")\n",
    "        if summary_div:\n",
    "            budget_row = summary_div.find(\"b\", string=re.compile(r\"Production(\\xa0| )Budget:\"))\n",
    "            if budget_row:\n",
    "                td = budget_row.find_next(\"td\")\n",
    "                if td:\n",
    "                    # Solo extraemos el número (ej. \"$6,000,000\")\n",
    "                    match = re.search(r\"\\$\\d[\\d,]*\", td.text)\n",
    "                    if match:\n",
    "                        budget = match.group(0).strip()\n",
    "\n",
    "        # Buscar la tabla con los ingresos\n",
    "        tables = soup.find_all(\"table\")\n",
    "        for table in tables:\n",
    "            # Domestic Box Office\n",
    "            domestic_element = table.find(string=re.compile(\"Domestic Box Office\", re.IGNORECASE))\n",
    "            if domestic_element:\n",
    "                row = domestic_element.find_parent(\"tr\")\n",
    "                if row:\n",
    "                    data_cells = row.find_all(\"td\", class_=\"data\")\n",
    "                    if data_cells:\n",
    "                        domestic_gross = data_cells[0].text.strip()\n",
    "            \n",
    "            # Worldwide Box Office\n",
    "            worldwide_element = table.find(string=re.compile(\"Worldwide Box Office\", re.IGNORECASE))\n",
    "            if worldwide_element:\n",
    "                row = worldwide_element.find_parent(\"tr\")\n",
    "                if row:\n",
    "                    data_cells = row.find_all(\"td\", class_=\"data\")\n",
    "                    if data_cells:\n",
    "                        worldwide_gross = data_cells[0].text.strip()\n",
    "        \n",
    "        logEvent(f\"Retrieved data for {movie_title} ({country_code}): Budget={budget}, Domestic={domestic_gross}, Worldwide={worldwide_gross}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logError(f\"Failed to retrieve box office data from The Numbers for {movie_title} ({country_code})\\n{repr(e)}\")\n",
    "    \n",
    "    return budget, domestic_gross, worldwide_gross\n",
    "\n",
    "def scrapeNationalAwards(movieURL: str, country_info: Dict) -> List[str]:\n",
    "    \"\"\"\n",
    "    Scrape national awards for any country from IMDb awards page.\n",
    "    Handles expandable award sections by interacting with \"more\" buttons.\n",
    "    Works with any award defined in the COUNTRIES dictionary.\n",
    "    \"\"\"\n",
    "    awardsURL = movieURL + \"awards/\"\n",
    "    awards = []\n",
    "    award_id = country_info[\"award_id\"]\n",
    "    award_name = country_info[\"award_name\"]\n",
    "    country_code = country_info[\"code\"]\n",
    "    \n",
    "    # Intentar primero con Selenium para manejar botones interactivos\n",
    "    try:\n",
    "        options = Options()\n",
    "        options.add_argument(\"--lang=en-US\")\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(awardsURL)\n",
    "        \n",
    "        # Esperar a que la página cargue\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"ipc-metadata-list\"))\n",
    "        )\n",
    "        \n",
    "        # Buscar la sección con el premio nacional específico\n",
    "        award_sections = driver.find_elements(By.XPATH, f\"//div[contains(@data-testid, 'sub-section-{award_id}')]\")\n",
    "        \n",
    "        if not award_sections:\n",
    "            # Buscar por nombre si no encontramos por ID\n",
    "            award_sections = driver.find_elements(By.XPATH, f\"//span[contains(text(), '{award_name}')]/ancestor::div[contains(@data-testid, 'sub-section')]\")\n",
    "        \n",
    "        if award_sections:\n",
    "            award_section = award_sections[0]\n",
    "            \n",
    "            # Verificar si existe algún botón \"más\" o \"more\" o similar\n",
    "            more_buttons = award_section.find_elements(By.XPATH, \".//button[contains(@class, 'ipc-see-more__button')]\")\n",
    "            \n",
    "            # Si existe el botón expandir, haz clic en él\n",
    "            if more_buttons:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_buttons[0])\n",
    "                driver.execute_script(\"arguments[0].click();\", more_buttons[0])\n",
    "                time.sleep(1)  # Esperar a que se carguen los elementos\n",
    "            \n",
    "            # Términos que indican ganador en varios idiomas\n",
    "            winner_terms = [\"Winner\", \"Ganador\", \"Ganadora\", \"Won\"]\n",
    "            \n",
    "            # Ahora extrae todos los premios\n",
    "            award_items = award_section.find_elements(By.XPATH, \".//li[contains(@class, 'ipc-metadata-list-summary-item')]\")\n",
    "            \n",
    "            for item in award_items:\n",
    "                # Verificar si es ganador\n",
    "                if any(term in item.text for term in winner_terms):\n",
    "                    # Intenta varias estrategias para encontrar la categoría\n",
    "                    \n",
    "                    # Estrategia 1: Clase específica para categoría\n",
    "                    category_elements = item.find_elements(By.XPATH, \".//span[contains(@class, 'awardCategoryName')]\")\n",
    "                    \n",
    "                    if category_elements:\n",
    "                        category = category_elements[0].text.strip()\n",
    "                        awards.append(category)\n",
    "                        continue\n",
    "                    \n",
    "                    # Estrategia 2: Buscar en listas inline con términos comunes de categorías\n",
    "                    category_terms = [\"Best\", \"Mejor\", \"Outstanding\", \"Excellence\", \"Award for\"]\n",
    "                    category_xpath = \".//li[contains(@class, 'ipc-inline-list__item')]//span[\" + \" or \".join([f\"contains(text(), '{term}')\" for term in category_terms]) + \"]\"\n",
    "                    category_elements = item.find_elements(By.XPATH, category_xpath)\n",
    "                    \n",
    "                    if category_elements:\n",
    "                        category = category_elements[0].text.strip()\n",
    "                        awards.append(category)\n",
    "                        continue\n",
    "                    \n",
    "                    # Estrategia 3: Buscar cualquier span dentro de un li de lista inline\n",
    "                    category_elements = item.find_elements(By.XPATH, \".//li[contains(@class, 'ipc-inline-list__item')]//span\")\n",
    "                    if category_elements:\n",
    "                        # Tomar el primer span que parece contener una categoría\n",
    "                        for elem in category_elements:\n",
    "                            text = elem.text.strip()\n",
    "                            if text and len(text) > 5 and not any(term in text for term in winner_terms):\n",
    "                                awards.append(text)\n",
    "                                break\n",
    "        \n",
    "        driver.quit()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logError(f\"Error in Selenium award scraper for {country_code}: {repr(e)}\")\n",
    "        if 'driver' in locals():\n",
    "            driver.quit()\n",
    "    \n",
    "    # Si no pudimos extraer con Selenium o no encontramos nada, intentar con requests y BeautifulSoup\n",
    "    if not awards:\n",
    "        try:\n",
    "            logEvent(f\"Falling back to BeautifulSoup for {award_name} awards ({country_code})\")\n",
    "            response = requests.get(awardsURL, headers=httpHeaders)\n",
    "            response.raise_for_status()\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Buscar específicamente la sección con atributo data-testid que contiene el ID del premio\n",
    "            award_section = soup.find(\"div\", attrs={\"data-testid\": lambda v: v and f\"sub-section-{award_id}\" in v})\n",
    "            \n",
    "            if not award_section:\n",
    "                # Si no se encuentra con el ID específico, buscar por el texto del premio\n",
    "                award_spans = soup.find_all(\"span\", string=lambda s: s and award_name in s)\n",
    "                for span in award_spans:\n",
    "                    section = span.find_parent(\"div\", attrs={\"data-testid\": lambda v: v and \"sub-section\" in v})\n",
    "                    if section:\n",
    "                        award_section = section\n",
    "                        break\n",
    "            \n",
    "            if award_section:\n",
    "                # Términos específicos de ganador según el idioma y país\n",
    "                winner_terms = [\"Winner\", \"Ganador\", \"Ganadora\", \"Won\"]\n",
    "                \n",
    "                # Buscar todos los items de la lista de premios\n",
    "                award_items = award_section.find_all(\"li\", class_=\"ipc-metadata-list-summary-item\")\n",
    "                \n",
    "                if not award_items:\n",
    "                    # Si no encuentra con ese selector, buscar con uno más general\n",
    "                    award_items = award_section.find_all(\"div\", class_=lambda c: c and \"ipc-metadata-list-summary-item\" in c)\n",
    "                \n",
    "                for item in award_items:\n",
    "                    # Verificar si es ganador\n",
    "                    is_winner = any(term in item.text for term in winner_terms)\n",
    "                    if not is_winner:\n",
    "                        continue\n",
    "                    \n",
    "                    # Buscar la categoría del premio - estrategia 1\n",
    "                    category_span = item.find(\"span\", class_=lambda c: c and \"awardCategoryName\" in c)\n",
    "                    \n",
    "                    if category_span:\n",
    "                        category = category_span.text.strip()\n",
    "                        awards.append(category)\n",
    "                    else:\n",
    "                        # Buscar en elementos li dentro de listas inline - estrategia 2\n",
    "                        category_terms = [\"Best\", \"Mejor\", \"Outstanding\", \"Excellence\", \"Award for\"]\n",
    "                        for li in item.find_all(\"li\", class_=\"ipc-inline-list__item\"):\n",
    "                            for span in li.find_all(\"span\"):\n",
    "                                if any(term in span.text for term in category_terms):\n",
    "                                    category = span.text.strip()\n",
    "                                    awards.append(category)\n",
    "                                    break\n",
    "                            if len(awards) > 0 and awards[-1] != category:\n",
    "                                break\n",
    "        except Exception as e:\n",
    "            logError(f\"Error in BeautifulSoup award scraper for {country_code}: {repr(e)}\")\n",
    "    \n",
    "    # Eliminar duplicados mientras preserva el orden\n",
    "    unique_awards = []\n",
    "    for award in awards:\n",
    "        if award not in unique_awards:\n",
    "            unique_awards.append(award)\n",
    "    \n",
    "    # Registrar resultados para depuración\n",
    "    if unique_awards:\n",
    "        logEvent(f\"Found {len(unique_awards)} {award_name} awards for a {country_code} movie: {unique_awards}\")\n",
    "    else:\n",
    "        logEvent(f\"No {award_name} awards found for a {country_code} movie\")\n",
    "        \n",
    "    return unique_awards\n",
    "# Generic entity saver/loader functions\n",
    "def saveEntityListAsJSON(entities: List, filename: str):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump([asdict(e) for e in entities], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def saveEntityListAsCSV(entities: List, filename: str):\n",
    "    if not entities:\n",
    "        return\n",
    "    with open(filename, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=asdict(entities[0]).keys())\n",
    "\n",
    "        writer.writeheader()\n",
    "        for e in entities:\n",
    "            writer.writerow(asdict(e))\n",
    "\n",
    "def scrape_country_movies(country_info: Dict) -> List[MovieInfo]:\n",
    "    \"\"\"\n",
    "    Función para scrapear películas de un país específico\n",
    "    \"\"\"\n",
    "    country_code = country_info[\"code\"]\n",
    "    country_name = country_info[\"name\"]\n",
    "    \n",
    "    print(f\"Scraping movies from {country_name}...\")\n",
    "    movies = scrapeIMDbMoviesWithSlidingWindow(country_info)\n",
    "    \n",
    "    print(f\"Found {len(movies)} movies from {country_name}\")\n",
    "    print(f\"Enriching with credits, financial data, and {country_info['award_name']}...\")\n",
    "    \n",
    "    for movie in tqdm(movies):\n",
    "        # Get credits\n",
    "        directors, thespians = scrapeMovieCredits(movie.url)\n",
    "        movie.directors = directors\n",
    "        movie.thespians = thespians\n",
    "        \n",
    "        # Get financial data from The Numbers\n",
    "        # Extract movie title and try to determine year\n",
    "        title = movie.title\n",
    "        year_match = re.search(r\"\\((\\d{4})\\)\", title)\n",
    "        year = year_match.group(1) if year_match else \"2024\"\n",
    "        \n",
    "        budget, domestic, worldwide = getBoxOfficeDataFromTheNumbers(title, country_code, year)\n",
    "        movie.budget = budget\n",
    "        movie.domesticGross = domestic\n",
    "        movie.worldwideGross = worldwide\n",
    "        \n",
    "        # Get national awards\n",
    "        awards = scrapeNationalAwards(movie.url, country_info)\n",
    "        movie.awards = awards\n",
    "        \n",
    "        # Respect the website's rate limits\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Save data for this country\n",
    "    saveEntityListAsJSON(movies, f'movies_{country_code.lower()}.json')\n",
    "    saveEntityListAsCSV(movies, f'movies_{country_code.lower()}.csv')\n",
    "    \n",
    "    return movies\n",
    "\n",
    "def main():\n",
    "    all_movies = []\n",
    "    \n",
    "    # Scrapear para cada país\n",
    "    for country_code, country_info in COUNTRIES.items():\n",
    "        country_movies = scrape_country_movies(country_info)\n",
    "        all_movies.extend(country_movies)\n",
    "        \n",
    "        # Pausa entre países para evitar sobrecarga de servidores\n",
    "        if country_code != list(COUNTRIES.keys())[-1]:  # Si no es el último país\n",
    "            print(f\"Pausing between countries...\")\n",
    "            time.sleep(5)\n",
    "    \n",
    "    # Guardar todos los datos combinados\n",
    "    saveEntityListAsJSON(all_movies, 'movies_all_countries.json')\n",
    "    saveEntityListAsCSV(all_movies, 'movies_all_countries.csv')\n",
    "    print(f\"Done! Scraped {len(all_movies)} movies from all countries with their data.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "programming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
